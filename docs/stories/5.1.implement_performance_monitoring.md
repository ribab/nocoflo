# Story 5.1: Implement Performance Monitoring

## Epic Context
**Epic:** Epic 5: Performance Optimization and Testing  
**Epic Goal:** Ensure the system meets performance requirements and maintains reliability

## Story Details
**Priority:** Medium  
**Effort:** Medium  
**Dependencies:** Story 1.2 (Implement Plugin Manager with pluggy)

## User Story
As a developer,
I want to implement comprehensive performance monitoring for the plugin system and application,
so that we can ensure the system meets performance requirements and identify optimization opportunities.

## Acceptance Criteria
1. Add performance monitoring for plugin system
2. Implement memory usage tracking
3. Create performance benchmarks for critical operations
4. Add logging for performance analysis
5. Implement caching strategies for frequently accessed data

## Integration Verification
- Performance monitoring doesn't impact system performance
- Memory usage stays within 20% increase requirement
- Performance data is useful for optimization

## Technical Requirements

### Performance Monitoring System
```python
# src/components/monitoring/performance_monitor.py
import time
import psutil
import threading
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import json
import logging

@dataclass
class PerformanceMetric:
    timestamp: datetime
    operation: str
    duration: float
    memory_usage: float
    cpu_usage: float
    plugin_name: Optional[str] = None
    error_count: int = 0

class PerformanceMonitor:
    def __init__(self):
        self.metrics: List[PerformanceMetric] = []
        self.start_time = time.time()
        self.monitoring_enabled = True
        self.cache = {}
        self.performance_thresholds = {
            'plugin_load_time': 2.0,  # seconds
            'memory_increase': 0.2,   # 20%
            'response_time': 1.0,     # seconds
            'cpu_usage': 0.8,         # 80%
        }
        
        # Start background monitoring
        self._start_background_monitoring()
    
    def monitor_operation(self, operation: str, plugin_name: Optional[str] = None):
        """Decorator to monitor operation performance"""
        def decorator(func):
            def wrapper(*args, **kwargs):
                start_time = time.time()
                start_memory = psutil.Process().memory_info().rss
                start_cpu = psutil.cpu_percent()
                
                try:
                    result = func(*args, **kwargs)
                    error_count = 0
                except Exception as e:
                    error_count = 1
                    logging.error(f"Error in {operation}: {str(e)}")
                    raise
                finally:
                    end_time = time.time()
                    end_memory = psutil.Process().memory_info().rss
                    end_cpu = psutil.cpu_percent()
                    
                    metric = PerformanceMetric(
                        timestamp=datetime.now(),
                        operation=operation,
                        duration=end_time - start_time,
                        memory_usage=end_memory - start_memory,
                        cpu_usage=end_cpu - start_cpu,
                        plugin_name=plugin_name,
                        error_count=error_count
                    )
                    
                    self.metrics.append(metric)
                    self._check_performance_thresholds(metric)
                
                return result
            return wrapper
        return decorator
    
    def _check_performance_thresholds(self, metric: PerformanceMetric):
        """Check if performance metrics exceed thresholds"""
        if metric.duration > self.performance_thresholds.get(f'{metric.operation}_time', float('inf')):
            logging.warning(f"Performance threshold exceeded for {metric.operation}: {metric.duration}s")
        
        if metric.memory_usage > self.performance_thresholds.get('memory_increase', float('inf')):
            logging.warning(f"Memory usage threshold exceeded: {metric.memory_usage} bytes")
    
    def _start_background_monitoring(self):
        """Start background monitoring thread"""
        def monitor_background():
            while self.monitoring_enabled:
                try:
                    self._collect_system_metrics()
                    time.sleep(30)  # Collect metrics every 30 seconds
                except Exception as e:
                    logging.error(f"Background monitoring error: {str(e)}")
        
        thread = threading.Thread(target=monitor_background, daemon=True)
        thread.start()
    
    def _collect_system_metrics(self):
        """Collect system-wide performance metrics"""
        current_time = datetime.now()
        
        # System metrics
        memory_percent = psutil.virtual_memory().percent
        cpu_percent = psutil.cpu_percent()
        disk_usage = psutil.disk_usage('/').percent
        
        # Application-specific metrics
        app_memory = psutil.Process().memory_info().rss
        app_cpu = psutil.Process().cpu_percent()
        
        system_metric = PerformanceMetric(
            timestamp=current_time,
            operation='system_monitoring',
            duration=0,
            memory_usage=app_memory,
            cpu_usage=app_cpu,
            error_count=0
        )
        
        self.metrics.append(system_metric)
        
        # Log if thresholds are exceeded
        if memory_percent > 80:
            logging.warning(f"High memory usage: {memory_percent}%")
        if cpu_percent > 80:
            logging.warning(f"High CPU usage: {cpu_percent}%")
    
    def get_performance_summary(self) -> Dict:
        """Get performance summary"""
        if not self.metrics:
            return {}
        
        recent_metrics = [m for m in self.metrics if (datetime.now() - m.timestamp).seconds < 3600]
        
        return {
            'total_operations': len(self.metrics),
            'recent_operations': len(recent_metrics),
            'average_duration': sum(m.duration for m in recent_metrics) / len(recent_metrics) if recent_metrics else 0,
            'total_memory_usage': sum(m.memory_usage for m in recent_metrics),
            'error_rate': sum(m.error_count for m in recent_metrics) / len(recent_metrics) if recent_metrics else 0,
            'uptime': time.time() - self.start_time,
        }
    
    def get_plugin_performance(self, plugin_name: str) -> Dict:
        """Get performance metrics for specific plugin"""
        plugin_metrics = [m for m in self.metrics if m.plugin_name == plugin_name]
        
        if not plugin_metrics:
            return {}
        
        return {
            'plugin_name': plugin_name,
            'total_operations': len(plugin_metrics),
            'average_duration': sum(m.duration for m in plugin_metrics) / len(plugin_metrics),
            'total_memory_usage': sum(m.memory_usage for m in plugin_metrics),
            'error_count': sum(m.error_count for m in plugin_metrics),
        }
    
    def export_metrics(self, filename: str):
        """Export performance metrics to file"""
        with open(filename, 'w') as f:
            json.dump([{
                'timestamp': m.timestamp.isoformat(),
                'operation': m.operation,
                'duration': m.duration,
                'memory_usage': m.memory_usage,
                'cpu_usage': m.cpu_usage,
                'plugin_name': m.plugin_name,
                'error_count': m.error_count,
            } for m in self.metrics], f, indent=2)
    
    def clear_metrics(self):
        """Clear performance metrics"""
        self.metrics.clear()
```

### Plugin Performance Monitoring
```python
# src/components/monitoring/plugin_monitor.py
from typing import Dict, List, Any
from .performance_monitor import PerformanceMonitor
import logging

class PluginPerformanceMonitor:
    def __init__(self, performance_monitor: PerformanceMonitor):
        self.performance_monitor = performance_monitor
        self.plugin_metrics = {}
        self.plugin_load_times = {}
        self.plugin_memory_usage = {}
    
    def monitor_plugin_operation(self, plugin_name: str, operation: str):
        """Decorator to monitor plugin operations"""
        return self.performance_monitor.monitor_operation(operation, plugin_name)
    
    def track_plugin_load(self, plugin_name: str, load_time: float, memory_usage: float):
        """Track plugin loading performance"""
        self.plugin_load_times[plugin_name] = load_time
        self.plugin_memory_usage[plugin_name] = memory_usage
        
        logging.info(f"Plugin {plugin_name} loaded in {load_time:.2f}s, memory: {memory_usage} bytes")
        
        # Check if plugin loading exceeds thresholds
        if load_time > 2.0:
            logging.warning(f"Plugin {plugin_name} took too long to load: {load_time:.2f}s")
        
        if memory_usage > 50 * 1024 * 1024:  # 50MB
            logging.warning(f"Plugin {plugin_name} using too much memory: {memory_usage} bytes")
    
    def get_plugin_performance_report(self) -> Dict:
        """Get comprehensive plugin performance report"""
        report = {
            'total_plugins': len(self.plugin_load_times),
            'average_load_time': sum(self.plugin_load_times.values()) / len(self.plugin_load_times) if self.plugin_load_times else 0,
            'total_memory_usage': sum(self.plugin_memory_usage.values()),
            'slow_plugins': [name for name, time in self.plugin_load_times.items() if time > 2.0],
            'memory_intensive_plugins': [name for name, memory in self.plugin_memory_usage.items() if memory > 50 * 1024 * 1024],
        }
        
        return report
```

### Caching System
```python
# src/components/caching/performance_cache.py
from typing import Any, Optional, Callable
import time
import threading
from collections import OrderedDict

class PerformanceCache:
    def __init__(self, max_size: int = 1000, ttl: int = 3600):
        self.max_size = max_size
        self.ttl = ttl
        self.cache = OrderedDict()
        self.lock = threading.Lock()
    
    def get(self, key: str) -> Optional[Any]:
        """Get value from cache"""
        with self.lock:
            if key in self.cache:
                value, timestamp = self.cache[key]
                if time.time() - timestamp < self.ttl:
                    # Move to end (most recently used)
                    self.cache.move_to_end(key)
                    return value
                else:
                    # Expired, remove
                    del self.cache[key]
            return None
    
    def set(self, key: str, value: Any):
        """Set value in cache"""
        with self.lock:
            if key in self.cache:
                # Update existing
                self.cache.move_to_end(key)
            else:
                # Check if cache is full
                if len(self.cache) >= self.max_size:
                    # Remove least recently used
                    self.cache.popitem(last=False)
            
            self.cache[key] = (value, time.time())
    
    def invalidate(self, key: str):
        """Invalidate cache entry"""
        with self.lock:
            if key in self.cache:
                del self.cache[key]
    
    def clear(self):
        """Clear all cache entries"""
        with self.lock:
            self.cache.clear()
    
    def get_stats(self) -> Dict:
        """Get cache statistics"""
        with self.lock:
            return {
                'size': len(self.cache),
                'max_size': self.max_size,
                'ttl': self.ttl,
            }
```

### Performance Dashboard
```python
# src/pages/admin/performance_dashboard.py
from nicegui import ui, app
from components.monitoring.performance_monitor import PerformanceMonitor
from components.monitoring.plugin_monitor import PluginPerformanceMonitor
from components.caching.performance_cache import PerformanceCache

@ui.page('/admin/performance')
def performance_dashboard():
    """Performance monitoring dashboard"""
    # Initialize monitors
    perf_monitor = PerformanceMonitor()
    plugin_monitor = PluginPerformanceMonitor(perf_monitor)
    cache = PerformanceCache()
    
    # Header
    with ui.header().classes('bg-primary text-white'):
        ui.label('Performance Dashboard').classes('text-xl font-bold')
    
    # Main content
    with ui.column().classes('w-full p-6'):
        # Performance overview
        with ui.card().classes('w-full mb-6'):
            ui.label('Performance Overview').classes('text-lg font-semibold mb-4')
            
            summary = perf_monitor.get_performance_summary()
            
            with ui.row().classes('w-full gap-4'):
                ui.card().classes('flex-1 p-4 bg-blue-50'):
                    ui.label(f"{summary.get('total_operations', 0)}").classes('text-2xl font-bold text-blue-600')
                    ui.label('Total Operations').classes('text-sm text-gray-600')
                
                ui.card().classes('flex-1 p-4 bg-green-50'):
                    ui.label(f"{summary.get('average_duration', 0):.2f}s").classes('text-2xl font-bold text-green-600')
                    ui.label('Avg Duration').classes('text-sm text-gray-600')
                
                ui.card().classes('flex-1 p-4 bg-yellow-50'):
                    ui.label(f"{summary.get('error_rate', 0):.1%}").classes('text-2xl font-bold text-yellow-600')
                    ui.label('Error Rate').classes('text-sm text-gray-600')
        
        # Plugin performance
        with ui.card().classes('w-full mb-6'):
            ui.label('Plugin Performance').classes('text-lg font-semibold mb-4')
            
            plugin_report = plugin_monitor.get_plugin_performance_report()
            
            with ui.table().classes('w-full'):
                ui.table_column('Plugin', 'plugin')
                ui.table_column('Load Time', 'load_time')
                ui.table_column('Memory Usage', 'memory')
                ui.table_column('Status', 'status')
                
                for plugin_name in plugin_report.get('slow_plugins', []):
                    with ui.table_row():
                        ui.table_cell(plugin_name)
                        ui.table_cell(f"{plugin_report['average_load_time']:.2f}s")
                        ui.table_cell(f"{plugin_report['total_memory_usage'] / 1024 / 1024:.1f}MB")
                        ui.table_cell(ui.badge('Slow', color='warning'))
        
        # Cache statistics
        with ui.card().classes('w-full mb-6'):
            ui.label('Cache Statistics').classes('text-lg font-semibold mb-4')
            
            cache_stats = cache.get_stats()
            
            with ui.row().classes('w-full gap-4'):
                ui.card().classes('flex-1 p-4 bg-purple-50'):
                    ui.label(f"{cache_stats['size']}").classes('text-2xl font-bold text-purple-600')
                    ui.label('Cache Entries').classes('text-sm text-gray-600')
                
                ui.card().classes('flex-1 p-4 bg-indigo-50'):
                    ui.label(f"{cache_stats['max_size']}").classes('text-2xl font-bold text-indigo-600')
                    ui.label('Max Size').classes('text-sm text-gray-600')
        
        # Performance actions
        with ui.card().classes('w-full'):
            ui.label('Performance Actions').classes('text-lg font-semibold mb-4')
            
            with ui.row().classes('w-full gap-2'):
                ui.button('Export Metrics', on_click=lambda: export_metrics())
                ui.button('Clear Cache', on_click=lambda: clear_cache())
                ui.button('Refresh', on_click=lambda: refresh_dashboard())
    
    def export_metrics():
        """Export performance metrics"""
        try:
            perf_monitor.export_metrics('performance_metrics.json')
            ui.notify('✅ Metrics exported successfully', type='positive')
        except Exception as e:
            ui.notify(f'❌ Failed to export metrics: {str(e)}', type='negative')
    
    def clear_cache():
        """Clear performance cache"""
        try:
            cache.clear()
            ui.notify('✅ Cache cleared successfully', type='positive')
        except Exception as e:
            ui.notify(f'❌ Failed to clear cache: {str(e)}', type='negative')
    
    def refresh_dashboard():
        """Refresh dashboard data"""
        ui.refresh()
```

## Implementation Tasks

### Task 1: Create Performance Monitoring System
- [ ] Create `src/components/monitoring/performance_monitor.py`
- [ ] Implement performance metric collection
- [ ] Add background monitoring
- [ ] Create performance thresholds

### Task 2: Implement Plugin Performance Monitoring
- [ ] Create `src/components/monitoring/plugin_monitor.py`
- [ ] Add plugin load time tracking
- [ ] Implement plugin memory usage monitoring
- [ ] Create plugin performance reports

### Task 3: Add Caching System
- [ ] Create `src/components/caching/performance_cache.py`
- [ ] Implement LRU cache
- [ ] Add cache invalidation
- [ ] Create cache statistics

### Task 4: Create Performance Dashboard
- [ ] Create `src/pages/admin/performance_dashboard.py`
- [ ] Implement performance overview
- [ ] Add plugin performance display
- [ ] Create cache statistics view

### Task 5: Integrate with Existing Components
- [ ] Add performance monitoring to plugin manager
- [ ] Integrate with table view operations
- [ ] Add monitoring to database operations
- [ ] Implement caching for frequently accessed data

### Task 6: Add Performance Logging
- [ ] Implement performance logging
- [ ] Add log rotation
- [ ] Create log analysis tools
- [ ] Add performance alerts

### Task 7: Testing
- [ ] Test performance monitoring
- [ ] Test caching system
- [ ] Test performance dashboard
- [ ] Test memory usage tracking

## Definition of Done
- [ ] Performance monitoring for plugin system is implemented
- [ ] Memory usage tracking is implemented
- [ ] Performance benchmarks for critical operations are created
- [ ] Logging for performance analysis is added
- [ ] Caching strategies for frequently accessed data are implemented
- [ ] Performance monitoring doesn't impact system performance
- [ ] Memory usage stays within 20% increase requirement
- [ ] Performance data is useful for optimization
- [ ] Tests cover performance monitoring functionality

## Risk Assessment
**Risk:** Performance monitoring may add overhead
**Mitigation:** Lightweight monitoring, configurable sampling, background processing

## Dependencies
- Story 1.2: Implement Plugin Manager with pluggy (must be completed first)

## Next Stories
- Story 5.3: Security and Error Handling
- Story 6.1: Create User Documentation 